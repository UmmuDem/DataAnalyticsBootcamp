{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9fd0f96",
   "metadata": {},
   "source": [
    "# Course Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887cb444",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90bab20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning and EDA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# build a model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# text analysis\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c2e3ba",
   "metadata": {},
   "source": [
    "## Bring in Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44fb14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96ece2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>instructor</th>\n",
       "      <th>level</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>no_of_students</th>\n",
       "      <th>rating</th>\n",
       "      <th>no_of_rating</th>\n",
       "      <th>about</th>\n",
       "      <th>syllabus</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Meditation: A way to achieve your goals in you...</td>\n",
       "      <td>Duck-Joo Lee</td>\n",
       "      <td>Beginner Level</td>\n",
       "      <td>Arts and Humanities</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>78489</td>\n",
       "      <td>4.6</td>\n",
       "      <td>843</td>\n",
       "      <td>Do we truly think that we have lived for ourse...</td>\n",
       "      <td>['Self- reflection is the methodology of medit...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               name  \\\n",
       "0           0  Meditation: A way to achieve your goals in you...   \n",
       "\n",
       "     instructor           level             category subcategory  \\\n",
       "0  Duck-Joo Lee  Beginner Level  Arts and Humanities  Philosophy   \n",
       "\n",
       "   no_of_students  rating  no_of_rating  \\\n",
       "0           78489     4.6           843   \n",
       "\n",
       "                                               about  \\\n",
       "0  Do we truly think that we have lived for ourse...   \n",
       "\n",
       "                                            syllabus language  \n",
       "0  ['Self- reflection is the methodology of medit...  English  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512a2048",
   "metadata": {},
   "source": [
    "## Data Cleaning/Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1b1c6c",
   "metadata": {},
   "source": [
    "- Explain cleaning and wrangling procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "219f7b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english')+ ['homework','quiz','week','version','want','introduction','use', 'learn'\n",
    "             'what','have','well'])\n",
    "MIN_WORDS = 4\n",
    "MAX_WORDS = 200\n",
    "\n",
    "PATTERN_S = re.compile(\"\\'s\")  # matches `'s` from text  \n",
    "PATTERN_RN = re.compile(\"\\\\r\\\\n\") #matches `\\r` and `\\n`\n",
    "PATTERN_PUNC = re.compile(r\"[^\\w\\s0-9]\") # matches all non A-z whitespace\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Series of cleaning. String to lower case, remove non words characters and numbers.\n",
    "        text (str): input text\n",
    "    return (str): modified initial text\n",
    "    \"\"\"\n",
    "    text = text.lower()  # lowercase text\n",
    "    text = re.sub(PATTERN_S, ' ', text)\n",
    "    text = re.sub(PATTERN_RN, ' ', text)\n",
    "    text = re.sub(PATTERN_PUNC, ' ', text)\n",
    "    return text\n",
    "\n",
    "def tokenizer(sentence, min_words=MIN_WORDS, max_words=MAX_WORDS, stopwords=STOPWORDS, lemmatize=False):\n",
    "    \"\"\"\n",
    "    Lemmatize, tokenize, crop and remove stop words.\n",
    "    \"\"\"\n",
    "    if lemmatize:\n",
    "        stemmer = WordNetLemmatizer()\n",
    "        tokens = [stemmer.lemmatize(w) for w in word_tokenize(sentence)]\n",
    "    else:\n",
    "        tokens = [w.lower() for w in word_tokenize(sentence)]\n",
    "    tokens = [w for w in tokens if (len(w) > min_words and len(w) < max_words\n",
    "                                                        and w not in stopwords)]\n",
    "    return tokens    \n",
    "\n",
    "\n",
    "def clean_syllabus(df):\n",
    "    \"\"\"\n",
    "    Remove irrelavant characters (in new column clean_sentence).\n",
    "    Lemmatize, tokenize words into list of words (in new column tok_lem_sentence).\n",
    "    \"\"\"\n",
    "    df['clean_syllabus'] = df['syllabus'].apply(clean_text)\n",
    "    df['clean_syl'] = df['clean_syllabus'].apply(\n",
    "        lambda x: tokenizer(x, min_words=MIN_WORDS, max_words=MAX_WORDS, stopwords=STOPWORDS, lemmatize=True))\n",
    "    return df\n",
    "    \n",
    "df = clean_syllabus(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85044e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5df75421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reflection',\n",
       " 'methodology',\n",
       " 'meditation',\n",
       " 'growth',\n",
       " 'happiness',\n",
       " 'human',\n",
       " 'completion',\n",
       " 'reflection',\n",
       " 'academic',\n",
       " 'research',\n",
       " 'reflection',\n",
       " 'graph',\n",
       " 'ultimate',\n",
       " 'purpose',\n",
       " 'reflection',\n",
       " 'learn',\n",
       " 'principle',\n",
       " 'reflection',\n",
       " 'practice',\n",
       " 'reflection',\n",
       " 'subject',\n",
       " 'methodology',\n",
       " 'reflection',\n",
       " 'practice',\n",
       " 'reflection',\n",
       " 'essential',\n",
       " 'subject',\n",
       " 'barrier',\n",
       " 'relationship',\n",
       " 'inferiority',\n",
       " 'childhood',\n",
       " 'emotion',\n",
       " 'hatred',\n",
       " 'since',\n",
       " 'childhood',\n",
       " 'worry',\n",
       " 'response',\n",
       " 'problem',\n",
       " 'current',\n",
       " 'recognize',\n",
       " 'copied',\n",
       " 'world',\n",
       " 'world',\n",
       " 'think',\n",
       " 'living',\n",
       " 'principle',\n",
       " 'formation',\n",
       " 'human',\n",
       " 'recognition',\n",
       " 'observed',\n",
       " 'philosopher',\n",
       " 'neuroscientist',\n",
       " 'understanding',\n",
       " 'reason',\n",
       " 'human',\n",
       " 'original',\n",
       " 'learn',\n",
       " 'practice',\n",
       " 'methodology',\n",
       " 'cleansing',\n",
       " 'change',\n",
       " 'methodology',\n",
       " 'cleansing',\n",
       " 'repetition',\n",
       " 'reflection',\n",
       " 'essential',\n",
       " 'subject',\n",
       " 'potential',\n",
       " 'positive',\n",
       " 'learn',\n",
       " 'practice',\n",
       " 'methodology',\n",
       " 'reflection',\n",
       " 'cleansing',\n",
       " 'everyday',\n",
       " 'stress',\n",
       " 'impetus',\n",
       " 'growth',\n",
       " 'study',\n",
       " 'overcoming',\n",
       " 'health',\n",
       " 'relationship',\n",
       " 'brain',\n",
       " 'change',\n",
       " 'meaning',\n",
       " 'reflection',\n",
       " 'cleansing',\n",
       " 'start',\n",
       " 'peaceful',\n",
       " 'wisdom',\n",
       " 'graph',\n",
       " 'people',\n",
       " 'school',\n",
       " 'office',\n",
       " 'practicing',\n",
       " 'reflection',\n",
       " 'continuously',\n",
       " 'meaning',\n",
       " 'reflection',\n",
       " 'social',\n",
       " 'aspect',\n",
       " 'reflection',\n",
       " 'communication',\n",
       " 'relationship',\n",
       " 'starting',\n",
       " 'point',\n",
       " 'peaceful',\n",
       " 'wisdom',\n",
       " 'graph',\n",
       " 'human',\n",
       " 'completion',\n",
       " 'ultimate',\n",
       " 'purpose',\n",
       " 'human',\n",
       " 'completion',\n",
       " 'reflection',\n",
       " 'meditation',\n",
       " 'session',\n",
       " 'opinion',\n",
       " 'previous',\n",
       " 'meditation',\n",
       " 'learner',\n",
       " 'literature',\n",
       " 'reflection',\n",
       " 'leadership',\n",
       " 'reflection',\n",
       " 'world',\n",
       " 'peace',\n",
       " 'lecture',\n",
       " 'slide',\n",
       " 'inner',\n",
       " 'power',\n",
       " 'recovered',\n",
       " 'reflection',\n",
       " 'interview',\n",
       " 'scholar',\n",
       " 'education',\n",
       " 'exercise',\n",
       " 'reflection',\n",
       " 'practice',\n",
       " 'reflection',\n",
       " 'relationship',\n",
       " 'practice',\n",
       " 'reflection',\n",
       " 'practice',\n",
       " 'reflection',\n",
       " 'emotion',\n",
       " 'hatred',\n",
       " 'practice',\n",
       " 'reflection',\n",
       " 'worry',\n",
       " 'practice',\n",
       " 'reflection',\n",
       " 'response',\n",
       " 'current',\n",
       " 'state',\n",
       " 'future',\n",
       " 'lecture',\n",
       " 'material',\n",
       " 'world',\n",
       " 'human',\n",
       " 'recognition',\n",
       " 'observed',\n",
       " 'philosopher',\n",
       " 'human',\n",
       " 'recognition',\n",
       " 'observed',\n",
       " 'neuroscientist',\n",
       " 'interview',\n",
       " 'neuroscientist',\n",
       " 'human',\n",
       " 'illusion',\n",
       " 'principle',\n",
       " 'formation',\n",
       " 'human',\n",
       " 'original',\n",
       " 'understanding',\n",
       " 'reason',\n",
       " 'lecture',\n",
       " 'material',\n",
       " 'change',\n",
       " 'change',\n",
       " 'methodology',\n",
       " 'cleansing',\n",
       " 'change',\n",
       " 'repetition',\n",
       " 'reflection',\n",
       " 'pride',\n",
       " 'repetition',\n",
       " 'reflection',\n",
       " 'human',\n",
       " 'relationship',\n",
       " 'repetition',\n",
       " 'reflection',\n",
       " 'potential',\n",
       " 'positive',\n",
       " 'lecture',\n",
       " 'material',\n",
       " 'reflection',\n",
       " 'ordinary',\n",
       " 'stress',\n",
       " 'impetus',\n",
       " 'growth',\n",
       " 'study',\n",
       " 'overcoming',\n",
       " 'gravity',\n",
       " 'health',\n",
       " 'relationship',\n",
       " 'brain',\n",
       " 'change',\n",
       " 'meaning',\n",
       " 'reflection',\n",
       " 'cleansing',\n",
       " 'lecture',\n",
       " 'material',\n",
       " 'importance',\n",
       " 'reflection',\n",
       " 'meditation',\n",
       " 'expert',\n",
       " 'practice',\n",
       " 'subtraction',\n",
       " 'chronologically',\n",
       " 'meaning',\n",
       " 'reflection',\n",
       " 'social',\n",
       " 'aspect',\n",
       " 'subtraction',\n",
       " 'relationship',\n",
       " 'meaning',\n",
       " 'reflection',\n",
       " 'social',\n",
       " 'aspect',\n",
       " 'subtraction',\n",
       " 'communication',\n",
       " 'people',\n",
       " 'school',\n",
       " 'practicing',\n",
       " 'reflection',\n",
       " 'continuously',\n",
       " 'people',\n",
       " 'office',\n",
       " 'practicing',\n",
       " 'reflection',\n",
       " 'continuously',\n",
       " 'starting',\n",
       " 'point',\n",
       " 'peaceful',\n",
       " 'wisdom',\n",
       " 'lecture',\n",
       " 'material']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_syl'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10b722d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tekrar düşün\n",
    "\n",
    "df['abs_rating'] = round(df['rating'] * (df['no_of_rating'].apply(lambda x: math.log(x))),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "449bddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_best_indices(m, topk, mask=None):\n",
    "    \"\"\"\n",
    "    Use sum of the cosine distance over all tokens.\n",
    "    m (np.array): cos matrix of shape (nb_in_tokens, nb_dict_tokens)\n",
    "    topk (int): number of indices to return (from high to lowest in order)\n",
    "    \"\"\"\n",
    "    # return the sum on all tokens of cosinus for each sentence\n",
    "    if len(m.shape) > 1:\n",
    "        cos_sim = np.mean(m, axis=0) \n",
    "    else: \n",
    "        cos_sim = m\n",
    "    index = np.argsort(cos_sim)[::-1] # from highest idx to smallest score \n",
    "    if mask is not None:\n",
    "        assert mask.shape == m.shape\n",
    "        mask = mask[index]\n",
    "    else:\n",
    "        mask = np.ones(len(cos_sim))\n",
    "    mask = np.logical_or(cos_sim[index] != 0, mask) #eliminate 0 cosine distance\n",
    "    best_index = index[mask][:topk]\n",
    "    if cos_sim.max() < 0.2:\n",
    "        return [], cos_sim\n",
    "    return best_index, cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a39850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "03d92145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(911, 36848)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adapt stop words\n",
    "token_stop = tokenizer(' '.join(STOPWORDS), lemmatize=True)\n",
    "\n",
    "# Fit TFIDF\n",
    "vectorizer = TfidfVectorizer(stop_words=token_stop, tokenizer=tokenizer) \n",
    "tfidf_mat = vectorizer.fit_transform(df['syllabus'].values) # -> (num_sentences, num_vocabulary)\n",
    "tfidf_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c10c4d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03206104, 0.09206371, 0.01924251, 0.01262559, 0.02378162,\n",
       "       0.02325072, 0.03399636, 0.02506207, 0.02962282, 0.06876045,\n",
       "       0.01268014, 0.01382127, 0.02091406, 0.01632968, 0.01461547,\n",
       "       0.02875258, 0.02867158, 0.02875258, 0.01358341, 0.0223388 ,\n",
       "       0.08033139, 0.01946456, 0.10095621, 0.02033479, 0.01957958,\n",
       "       0.01946456, 0.01604378, 0.03399636, 0.01551874, 0.03399636,\n",
       "       0.01892769, 0.01216081, 0.00820885, 0.03064778, 0.03378374,\n",
       "       0.0319772 , 0.0223388 , 0.04232537, 0.03468152, 0.08886845,\n",
       "       0.07757829, 0.04182812, 0.03314282, 0.03648244, 0.07633235,\n",
       "       0.08625773, 0.01203936, 0.09413599, 0.02859428, 0.03584785,\n",
       "       0.02991309, 0.06799273, 0.05475889, 0.02028835, 0.06137581,\n",
       "       0.04013911, 0.01994226, 0.03568467, 0.02965154, 0.11206721,\n",
       "       0.0479665 , 0.19236623, 0.04279976, 0.0352112 , 0.02058311,\n",
       "       0.06799273, 0.05363451, 0.06901769, 0.07134485, 0.03653001,\n",
       "       0.01738006, 0.01461547, 0.04129973, 0.03399636, 0.03206104,\n",
       "       0.02836608, 0.01249188, 0.03084064, 0.06799273, 0.01826501,\n",
       "       0.05750516, 0.0230059 , 0.05088824, 0.03399636, 0.08802801,\n",
       "       0.02681725, 0.03277795, 0.06765291, 0.03399636, 0.10969474,\n",
       "       0.05067562, 0.06640697, 0.03635485, 0.04875806, 0.06765291,\n",
       "       0.01268014, 0.01800694, 0.83382475, 0.06582243, 0.12791149,\n",
       "       0.02407098, 0.04716564, 0.10726901, 0.1366381 , 0.05909231,\n",
       "       0.03399636])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mat[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "58f5823b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>abs_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, subcategory, abs_rating]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_recommendations_tfidf(sentence, tfidf_mat):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return the database sentences in order of highest cosine similarity relatively to each \n",
    "    token of the target sentence. \n",
    "    \"\"\"\n",
    "    # Embed the query sentence\n",
    "    tokens = [str(tok) for tok in word_tokenize(sentence)]\n",
    "    vec = vectorizer.transform(tokens)\n",
    "    # Create list with similarity between query and dataset\n",
    "    mat = cosine_similarity(vec, tfidf_mat)\n",
    "    # Best cosine distance for each token independantly\n",
    "    #print(mat.shape)\n",
    "    best_index, cos_sim = extract_best_indices(mat, topk=5)\n",
    "    return best_index, cos_sim\n",
    "\n",
    "query_sentence = 'Introduction to Structured Query Language'\n",
    "best_index, cos_sim = get_recommendations_tfidf(query_sentence, tfidf_mat)\n",
    "display(df[['name', 'subcategory','abs_rating']].iloc[best_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "cb296a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender():\n",
    "    response = input( \"\\033[1m\" + \"\"\"\n",
    "                        Welcome to the Coursera course recommender! (It contains only free courses.)\n",
    "                        Are you new here?(yes/no): \"\"\").lower().replace(\" \", '')\n",
    "    while response == 'yes':\n",
    "        query_sentence = input(\"\\033[1m\" + \"\"\"\n",
    "                        I am glad you prefer studying today!\n",
    "                        What do you want to learn? Give me some keywords that are important for you: \n",
    "                        \"\"\").lower()\n",
    "        best_index = get_recommendations_tfidf(query_sentence, tfidf_mat)[0]\n",
    "        if len(best_index)==0:\n",
    "            response = input(\"\\033[1m\" + \"\"\"\n",
    "                        Sorry, couldnt find a good match. Do you want to try again? (yes/no)\n",
    "                        \"\"\")\n",
    "            if response == 'yes':\n",
    "                print(\"\\033[1m\"+ \"\"\"\n",
    "                        This time please give more details.\n",
    "                        \"\"\")\n",
    "            if response == 'no':\n",
    "                print(\"\\033[1m\"+ \"\"\"\n",
    "                        Please don't quit on studying. See you later!\n",
    "                        \"\"\")\n",
    "            \n",
    "        elif len(best_index)!=0:\n",
    "            print(\"\\033[1m\"+\"\"\"\n",
    "                        We have three courses for you, choose according to your level: \"\"\")\n",
    "            for i in list(best_index):\n",
    "                course_name = df['name'].iloc[i]\n",
    "                instructor = df['instructor'].iloc[i]\n",
    "                level = df['level'].iloc[i]\n",
    "                print(\"\\033[1m\"+ \"\"\" \n",
    "                            {}: \n",
    "                            {} \n",
    "                            by {} \"\"\".format(level,\"\\u0332\".join(course_name),instructor))\n",
    "                    \n",
    "            response = 'no'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8d96db24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                        Welcome to the Coursera course recommender! (It contains only free courses.)\n",
      "                        Are you new here?(yes/no): yes\n",
      "\n",
      "                        I am glad you prefer studying today!\n",
      "                        What do you want to learn? Give me some keywords that are important for you: \n",
      "                        data science\n",
      "\u001b[1m\n",
      "                        We have three courses for you, choose according to your level: \n",
      "\u001b[1m \n",
      "                            Beginner Level: \n",
      "                            S̲o̲c̲i̲a̲l̲ ̲S̲c̲i̲e̲n̲c̲e̲ ̲A̲p̲p̲r̲o̲a̲c̲h̲e̲s̲ ̲t̲o̲ ̲t̲h̲e̲ ̲S̲t̲u̲d̲y̲ ̲o̲f̲ ̲C̲h̲i̲n̲e̲s̲e̲ ̲S̲o̲c̲i̲e̲t̲y̲ ̲P̲a̲r̲t̲ ̲1 \n",
      "                            by Cameron Campbell \n",
      "\u001b[1m \n",
      "                            Beginner Level: \n",
      "                            P̲h̲i̲l̲o̲s̲o̲p̲h̲y̲,̲ ̲S̲c̲i̲e̲n̲c̲e̲ ̲a̲n̲d̲ ̲R̲e̲l̲i̲g̲i̲o̲n̲:̲ ̲S̲c̲i̲e̲n̲c̲e̲ ̲a̲n̲d̲ ̲P̲h̲i̲l̲o̲s̲o̲p̲h̲y \n",
      "                            by Dr J Adam Carter \n",
      "\u001b[1m \n",
      "                            Beginner Level: \n",
      "                            T̲e̲a̲c̲h̲i̲n̲g̲ ̲S̲c̲i̲e̲n̲c̲e̲ ̲a̲t̲ ̲U̲n̲i̲v̲e̲r̲s̲i̲t̲y \n",
      "                            by Sara Taner \n",
      "\u001b[1m \n",
      "                            Beginner Level: \n",
      "                            S̲c̲i̲e̲n̲c̲e̲ ̲L̲i̲t̲e̲r̲a̲c̲y̲  \n",
      "                            by Dr. Claire Scavuzzo \n",
      "\u001b[1m \n",
      "                            Mixed Level: \n",
      "                            I̲n̲t̲r̲o̲d̲u̲c̲t̲i̲o̲n̲ ̲t̲o̲ ̲C̲o̲m̲m̲u̲n̲i̲c̲a̲t̲i̲o̲n̲ ̲S̲c̲i̲e̲n̲c̲e \n",
      "                            by Rutger de  Graaf \n"
     ]
    }
   ],
   "source": [
    "recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9facfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b306e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a934c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
